{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a48f06-54ef-4757-a4b2-40ac6816254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\".env\", \"w\") as f:\n",
    "    f.write(\"OPENAI_API_KEY=\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f3c84b-b991-4adc-ad0c-fb2b45d95e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d05be2-ce97-4904-bd6f-ee5158a4ec58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.69.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.11.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.13.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "344e3f4b-b7a5-466e-98eb-28b16f71898d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.49)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.13.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e7ce20-cd8b-431a-a104-b2ff0dd11b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e5fbcd-a1ee-4b9f-bb5c-19b04161f1a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/workspace/.env\")  # .env íŒŒì¼ ê²½ë¡œ ëª…ì‹œ\n",
    "\n",
    "import os\n",
    "# print(\"OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\"))  # í™•ì¸ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a18d52e-facc-41d8-8aa9-5e4c1253818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /workspace\n",
      "Files: ['.ipynb_checkpoints', 'gradio.ipynb', 'special_tokens_map.json', 'README.md', 'adapter_config.json', 'tokenizer_config.json', 'tokenizer.json', 'adapter_model.safetensors', 'streamlit_app.py', 'koalpacarun.ipynb', 'bank_faq.json', 'Untitled.ipynb', 'cleaned_data.json', 'finetune_dataset.json', 'koalpaca_lora_output', '.env', 'test.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "# í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìˆëŠ” íŒŒì¼ ëª©ë¡\n",
    "print(\"Files:\", os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f8066b-2c5a-43bc-8337-d77a7bfe821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = \"/workspace/.env\"  # RunPod ê¸°ë³¸ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€\n",
    "with open(env_path, \"w\") as f:\n",
    "    f.write(\"OPENAI_API_KEY=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc4450cc-e912-4643-899b-1d8e13fb2172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # âœ… Transformers + PEFT (LoRA)\n",
    "# !pip install transformers accelerate peft bitsandbytes --upgrade\n",
    "\n",
    "# # âœ… Datasets (fine-tuning ë°ì´í„°ì…‹ ì²˜ë¦¬)\n",
    "# !pip install datasets\n",
    "\n",
    "# # âœ… LangChain + ChromaDB\n",
    "# !pip install langchain langchain-community chromadb\n",
    "\n",
    "# # âœ… Hugging Face Hub (í† í° ì‚¬ìš© ì‹œ)\n",
    "# !pip install huggingface_hub\n",
    "\n",
    "# # âœ… dotenv (í† í° ë³´ì•ˆ ì €ì¥ìš©)\n",
    "# !pip install python-dotenv\n",
    "\n",
    "# # âœ… ê¸°íƒ€: tqdm, safetensors\n",
    "# !pip install tqdm safetensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "291d8b46-148d-4d2a-8d6c-0823b9d52769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (2.2.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6831a827-9d83-47cc-97ee-fcd82b3da3a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1053, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 737, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 513, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3046, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3101, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3488, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2558/3781546988.py\", line 1, in <module>\n",
      "    from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\", line 27, in <module>\n",
      "    from .chat_template_utils import DocstringParsingException, TypeHintParsingException, get_json_schema\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/chat_template_utils.py\", line 40, in <module>\n",
      "    from torch import Tensor\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a5dcdf498142419048cb548b9a9880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m     13\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### ì§ˆë¬¸:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mì£¼íƒì²­ì•½ ë‹´ë³´ëŒ€ì¶œì´ ê°€ëŠ¥í•œê°€ìš”?\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### ë‹µë³€:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py:287\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1371\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1364\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1365\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1368\u001b[0m         )\n\u001b[1;32m   1369\u001b[0m     )\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1379\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1377\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m   1378\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m-> 1379\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py:434\u001b[0m, in \u001b[0;36mTextGenerationPipeline.postprocess\u001b[0;34m(self, model_outputs, return_type, clean_up_tokenization_spaces, continue_final_message)\u001b[0m\n\u001b[1;32m    432\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m model_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    433\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m model_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 434\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mgenerated_sequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    435\u001b[0m records \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    436\u001b[0m other_outputs \u001b[38;5;241m=\u001b[39m model_outputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "base_model_name = \"beomi/KoAlpaca-Polyglot-5.8B\"\n",
    "adapter_path = \"./koalpaca_lora_output\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, use_fast=False)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512)\n",
    "\n",
    "prompt = \"### ì§ˆë¬¸:\\nì£¼íƒì²­ì•½ ë‹´ë³´ëŒ€ì¶œì´ ê°€ëŠ¥í•œê°€ìš”?\\n\\n### ë‹µë³€:\\n\"\n",
    "result = pipe(prompt)\n",
    "print(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e14507-aa42-43c8-bb4d-e409fd38244d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d79ed1ac9c45459d36b550949c7d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ì§ˆë¬¸:\n",
      "ì£¼íƒì²­ì•½ ë‹´ë³´ëŒ€ì¶œì´ ê°€ëŠ¥í•œê°€ìš”?\n",
      "\n",
      "### ë‹µë³€:\n",
      "ë‹´ë³´ë¶€ë™ì‚°ê³¼ ê·¼ì €ë‹¹ê¶Œì„¤ì •ê¸ˆì•¡ì„ í¬í•¨í•˜ì—¬ ì£¼íƒì„ëŒ€ì°¨ê³„ì•½ì„œë¡œ ì „ì…ì‹ ê³ ë¥¼ í•˜ê³  ì‚´ê¸° ì‹œì‘í•˜ê±°ë‚˜, í™•ì •ì¼ìë¥¼ ë°›ì€ ê²½ìš°ì—ëŠ” ì£¼íƒìê¸ˆìƒí™˜ìˆ˜ìˆ˜ê·  ë“± ì¼ëª… â€˜ì „ì„¸ê¸ˆë³´í˜¸ë¡ â€™ìœ¼ë¡œ ë¶ˆë¦¬ìš°ëŠ” ë³´ì¦ì„œê°€ ë°œê¸‰ë˜ì–´ ìˆë‹¤ë©´ ì£¼íƒë³´ì¦ë¶€ ì „ì„¸ìê¸ˆ ëŒ€ì¶œë¡œ ì·¨ê¸‰ë©ë‹ˆë‹¤. ë‹¨, ì€í–‰ì—ì„œ ì •í•œ ì¡°ê±´(ì˜ˆ : ì„ì°¨ëª©ì ë¬¼ì˜ ì„ ìˆœìœ„ ì„¤ì • ë˜ëŠ” ì±„ê¶Œë³´ì „ ì¡°ì¹˜ í›„ ìƒí™˜ì‹¤ì  ë³´ìœ  ì—¬ë¶€ë“±)ì„ ì¶©ì¡±ì‹œ ë¹„ì ìš© ì˜ˆì™¸ ëŒ€ìƒìœ¼ë¡œ ê²€í† í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "ê³ ê°ë‹˜ê»˜ì„œ ì¶”ê°€ì ìœ¼ë¡œ ë¬¸ì˜ì‚¬í•­ì´ë‚˜ ê¸ˆìœµì •ë³´ì œê³µ í•„ìš” ì‹œ ì˜ì—…ì  ë°©ë¬¸ ìƒë‹´ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "ìœ„ ë‚´ìš© ì™¸ì—ë„ ê¶ê¸ˆí•˜ì‹  ì‚¬í•­ì´ë‚˜ ìƒì„¸í•œ ìƒë‹´ì„œë¹„ìŠ¤ ì´ìš©ì„ ì›í•˜ì‹ ë‹¤ë©´ ê³ ê°ìƒë‹´ì„¼í„°(1588-3206/0674) ë° ì˜ì—…ì  ë°©ë¬¸ìƒë‹´ 1544~031900ë²ˆìœ¼ë¡œ ì—°ë½ì£¼ì‹œë©´ ì¹œì ˆí•˜ê³  ì •í™•í•œ ìƒë‹´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ë³¸ ì„œë¹„ìŠ¤ëŠ” 2020.09.10ë¶€í„° ~ 2022.08.31ê¹Œì§€ ë¬´ë£Œ ì œê³µ ì¤‘ì…ë‹ˆë‹¤.â˜ ìƒê¸°ì„œë¹„ìŠ¤ëŠ” ë§Œ 19ì„¸ ì´ìƒ ì„œìš¸íŠ¹ë³„ì‹œ ê³µê³µì„ëŒ€ì•„íŒŒíŠ¸ ì „ì„¸ëŒ€ì¶œ ëŒ€ìƒìì—ê²Œë§Œ í•´ë‹¹í•©ë‹ˆë‹¤. â˜ ì„œìš¸ì‹œ ì „ì›”ì„¸ë³´ì¦ê¸ˆì˜ 0% ì´ë‚´, ì›” ì„ì°¨ë£Œì˜ 12%(ë¬´ìë…€ ê°€êµ¬ì¸ ê²½ìš° 13%)ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.â˜ ì—°ë§ì •ì‚°ìš© ì£¼íƒê¸ˆìœµì‹ ìš©ë³´ì¦ê¸°ê¸ˆ ë§Œê¸°ì—°ì¥ì„œë¹„ìŠ¤*ëŒ€ìƒìëŠ” ë³¸ì¸ê³µì œ í•©ê³„ì•¡ ê³„ì‚°í•˜ì—¬ ì›ê¸ˆë¶€ë‹´ ì—†ìœ¼ë©° ì´ìì§€ì› ê¸°ê°„ì€ 1ë…„ (2021.01.1 ~ 2023.12.30), ì—°ì¥ê¸°ê°„ ì´í›„ ë¶„í• ë‚©ë¶€ ì›í•´ìš”ì‹¤ ë•ŒëŠ” ìµœì¥ 10ë…„ ì´ˆê³¼ ë¶ˆê°€í•©ë‹ˆë‹¤.â€» ìš°ë¦¬ì€í–‰ê³¼ ê³„ì•½ì²´ê²°ëœ ë¶€ê°€ì„œë¹„ìŠ¤ ì´ìš©ìë„ ë™ì¼í•˜ê²Œ ì ìš©ë©ë‹ˆë‹¤.\n",
      "ìƒí’ˆë‚´ìš© ë°”ë¡œ ê°€ê¸°<ìì„¸íˆ ë³´ê¸°>\n",
      "íŠ¹ì•½ê°€ì…ì‹ ì²­ ì´ìš©ì•ˆë‚´\n",
      "ì‹ ê·œ ê°€ì… ì‹ ì²­ ì•ˆë‚´(2023.02.3.7~ 2024.2.17.9.14)\n",
      "ê°œì¸ë³„ ë¶€ë™ì‚° ì •ë³´ë³€ë™ ì¡°íšŒ(21.11.27~24.32.16)\n",
      "ê³„ì¢Œì´ë™ë°©ë²• ì•ˆë‚´\n",
      "í•œêµ­ì£¼íƒê¸ˆìœµê³µì‚¬ í™ˆí˜ì´ì§€ ìƒë‹´ì‚¬ë¡€ ì„œë¹„ìŠ¤ ì´ìš© ë°©ë²•\tì—°ì¤‘ê¸ˆë¦¬ì¡°íšŒ\tì „ì²´ë³´ê¸°\tHTML CSS ì „ì²´ë³´ê¸° ê²€ìƒ‰ê²°ê³¼ ì¸ê¸°ì—°ì¬ ë°°ë„ˆë‹«ê¸°\n",
      "ì• ì¸ë§Œë“¤ê¸° ì»¨í…ì¸ \n",
      "ë” ë§ì€ ìƒí’ˆì„ ë§Œë‚˜ë³´ì„¸ìš”!\n",
      "êµ¬ë¶„ ********(8) ì‹ ê·œ ê°€ì…ì‹ ì²­ì í•„ìˆ˜ìš”ê±´ í™•ì¸ì—¬ë¶€ *******\n",
      "ì„œìš¸ì‹œì²­ì²­ë…„ì·¨ì—…ì§€ì›ì‚¬ì—… ì„œë¥˜ì „í˜• í•©ê²©ì—¬ë¶€ í•„ì¦ë°œê¸‰\n",
      "ë¯¸ì„±ë…„ìì˜ ê²½ìš° ë¶€ëª¨ì™€ í•¨ê»˜ ì…êµ­ì‚¬ì‹¤í™•ì¸ì„œë¥˜ ì œì¶œ\n",
      "ë³¸ì¸\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "model_path = \"./koalpaca_lora_output\"\n",
    "base_model = \"beomi/KoAlpaca-Polyglot-5.8B\"\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½ ì„¤ì •)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",      # ìë™ ë¶„ì‚°\n",
    "    torch_dtype=\"auto\"      # float16 ìë™ ì„¤ì •\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "prompt = \"### ì§ˆë¬¸:\\nì£¼íƒì²­ì•½ ë‹´ë³´ëŒ€ì¶œì´ ê°€ëŠ¥í•œê°€ìš”?\\n\\n### ë‹µë³€:\\n\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.pop(\"token_type_ids\", None)  # âŒ GPT ê³„ì—´ì—” ë¶ˆí•„ìš”\n",
    "\n",
    "# ì…ë ¥ í…ì„œë¥¼ ëª¨ë¸ê³¼ ë™ì¼í•œ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "device = model.device\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ìƒì„±\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,               # ğŸ”¹ ì‘ë‹µ ê¸¸ì´ ì¶©ë¶„íˆ í™•ë³´\n",
    "    temperature=0.7,                  # ğŸ”¹ ì ë‹¹í•œ ì°½ì˜ì„±\n",
    "    top_p=0.95,                       # ğŸ”¹ í™•ë¥  ëˆ„ì  ìƒìœ„ í† í°ë§Œ ì„ íƒ\n",
    "    do_sample=True,                   # ğŸ”¹ ìƒ˜í”Œë§ ê¸°ë°˜ ìƒì„± (greedy ë°©ì§€)\n",
    "    repetition_penalty=1.3,          # ğŸ”‘ ë°˜ë³µ ì–µì œ í•µì‹¬ ì˜µì…˜\n",
    "    no_repeat_ngram_size=4,          # ğŸ”‘ 4ê·¸ë¨ ë°˜ë³µ ë°©ì§€\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "\n",
    "# ì¶œë ¥\n",
    "generated = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65be38e7-6d24-49f7-b4bb-b3b136aeb624",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2558/831949170.py:41: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ZeroShotAgent does not support multi-input tool ì „ì„¸ëŒ€ì¶œí•œë„ê³„ì‚°ê¸°.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# âœ… Agent ì´ˆê¸°í™”\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAgentType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZERO_SHOT_REACT_DESCRIPTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# âœ… ì‹¤í–‰ ì˜ˆì‹œ\u001b[39;00m\n\u001b[1;32m     49\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124më³´ì¦ê¸ˆ 300000000ì´ê³  ì—°ì†Œë“ 60000000, ì‹ ìš©ë“±ê¸‰ì€ ìƒì¸ë° ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ”?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     emit_warning()\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/initialize.py:73\u001b[0m, in \u001b[0;36minitialize_agent\u001b[0;34m(tools, llm, agent, callback_manager, agent_path, agent_kwargs, tags, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     agent_cls \u001b[38;5;241m=\u001b[39m AGENT_TO_CLASS[agent]\n\u001b[1;32m     72\u001b[0m     agent_kwargs \u001b[38;5;241m=\u001b[39m agent_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m---> 73\u001b[0m     agent_obj \u001b[38;5;241m=\u001b[39m \u001b[43magent_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm_and_tools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43magent_kwargs\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m agent_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     agent_obj \u001b[38;5;241m=\u001b[39m load_agent(\n\u001b[1;32m     78\u001b[0m         agent_path, llm\u001b[38;5;241m=\u001b[39mllm, tools\u001b[38;5;241m=\u001b[39mtools, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager\n\u001b[1;32m     79\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/mrkl/base.py:138\u001b[0m, in \u001b[0;36mZeroShotAgent.from_llm_and_tools\u001b[0;34m(cls, llm, tools, callback_manager, output_parser, prefix, suffix, format_instructions, input_variables, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_llm_and_tools\u001b[39m(\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    123\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Agent:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct an agent from an LLM and tools.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m        kwargs: Additional parameters to pass to the agent.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_prompt(\n\u001b[1;32m    140\u001b[0m         tools,\n\u001b[1;32m    141\u001b[0m         prefix\u001b[38;5;241m=\u001b[39mprefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m         input_variables\u001b[38;5;241m=\u001b[39minput_variables,\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    146\u001b[0m     llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    147\u001b[0m         llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m    148\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    149\u001b[0m         callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager,\n\u001b[1;32m    150\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/mrkl/base.py:162\u001b[0m, in \u001b[0;36mZeroShotAgent._validate_tools\u001b[0;34m(cls, tools)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_tools\u001b[39m(\u001b[38;5;28mcls\u001b[39m, tools: Sequence[BaseTool]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mvalidate_tools_single_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tools) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot no tools for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. At least one tool must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/utils.py:18\u001b[0m, in \u001b[0;36mvalidate_tools_single_input\u001b[0;34m(class_name, tools)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tool\u001b[38;5;241m.\u001b[39mis_single_input:\n\u001b[0;32m---> 18\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support multi-input tool \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: ZeroShotAgent does not support multi-input tool ì „ì„¸ëŒ€ì¶œí•œë„ê³„ì‚°ê¸°."
     ]
    }
   ],
   "source": [
    "# ì„¤ì¹˜\n",
    "!pip install langchain langchain-openai openai pydantic python-dotenv --quiet\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë”©\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# LangChain & OpenAI ì—°ë™\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# âœ… ì „ì„¸ëŒ€ì¶œ í•œë„ ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_jeonse_limit(deposit: int, income: int, credit_grade: str) -> str:\n",
    "    credit_multipliers = {\"ìƒ\": 0.8, \"ì¤‘\": 0.6, \"í•˜\": 0.4}\n",
    "    multiplier = credit_multipliers.get(credit_grade, 0.5)\n",
    "    limit = min(deposit * multiplier, income * 4)\n",
    "    return f\"ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ” ì•½ {int(limit):,}ì›ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "# âœ… ì…ë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜ (Pydantic)\n",
    "class JeonseLimitInput(BaseModel):\n",
    "    deposit: int\n",
    "    income: int\n",
    "    credit_grade: str\n",
    "\n",
    "# âœ… Tool ì •ì˜\n",
    "tool_1 = Tool.from_function(\n",
    "    name=\"ì „ì„¸ëŒ€ì¶œí•œë„ê³„ì‚°ê¸°\",\n",
    "    description=\"ë³´ì¦ê¸ˆ(deposit), ì—°ì†Œë“(income), ì‹ ìš©ë“±ê¸‰(credit_grade)ì„ ê¸°ë°˜ìœ¼ë¡œ ì „ì„¸ëŒ€ì¶œ í•œë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\",\n",
    "    args_schema=JeonseLimitInput,\n",
    "    func=calculate_jeonse_limit\n",
    ")\n",
    "\n",
    "tools = [tool_1]\n",
    "\n",
    "# âœ… OpenAI LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "# âœ… Agent ì´ˆê¸°í™”\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# âœ… ì‹¤í–‰ ì˜ˆì‹œ\n",
    "query = \"ë³´ì¦ê¸ˆ 300000000ì´ê³  ì—°ì†Œë“ 60000000, ì‹ ìš©ë“±ê¸‰ì€ ìƒì¸ë° ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ”?\"\n",
    "response = agent.run(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37371937-5ca3-4289-a3d0-b66ab9fa5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ì„¤ì¹˜\n",
    "!pip install langchain langchain-openai openai python-dotenv --quiet\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë”©\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# LangChain + OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import Tool, AgentType, initialize_agent\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# âœ… ì „ì„¸ëŒ€ì¶œ í•œë„ ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_jeonse_limit(deposit: int, income: int, credit_grade: str) -> str:\n",
    "    credit_multipliers = {\"ìƒ\": 0.8, \"ì¤‘\": 0.6, \"í•˜\": 0.4}\n",
    "    multiplier = credit_multipliers.get(credit_grade, 0.5)\n",
    "    limit = min(deposit * multiplier, income * 4)\n",
    "    return f\"ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ” ì•½ {int(limit):,}ì›ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "# âœ… ì…ë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "class JeonseLimitInput(BaseModel):\n",
    "    deposit: int\n",
    "    income: int\n",
    "    credit_grade: str\n",
    "\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "tool_1 = StructuredTool.from_function(\n",
    "    name=\"calculate_jeonse_limit\",\n",
    "    description=\"ë³´ì¦ê¸ˆ, ì—°ì†Œë“, ì‹ ìš©ë“±ê¸‰ì„ ë°›ì•„ ì „ì„¸ëŒ€ì¶œ í•œë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\",\n",
    "    args_schema=JeonseLimitInput,\n",
    "    func=calculate_jeonse_limit,\n",
    "    return_direct=True\n",
    ")\n",
    "\n",
    "\n",
    "# âœ… LLM ì—°ê²°\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "# âœ… ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ë©€í‹° ì¸í’‹ íˆ´ ì§€ì›)\n",
    "agent = initialize_agent(\n",
    "    tools=[tool_1],\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# âœ… ì‹¤í–‰ ì˜ˆì‹œ\n",
    "query = \"ë³´ì¦ê¸ˆ 3ì–µì´ê³  ì—°ì†Œë“ 6ì²œë§Œì›, ì‹ ìš©ë“±ê¸‰ì€ ìƒì¸ë° ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ”?\"\n",
    "response = agent.run(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad0056-4f68-4615-9875-b9c8d28f6954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ì›” ìƒí™˜ê¸ˆ ê³„ì‚° í•¨ìˆ˜ ì •ì˜\n",
    "def calculate_monthly_payment(principal: int, annual_rate: float, years: int) -> str:\n",
    "    monthly_rate = annual_rate / 12 / 100\n",
    "    months = years * 12\n",
    "    if monthly_rate == 0:\n",
    "        monthly_payment = principal / months\n",
    "    else:\n",
    "        monthly_payment = principal * (monthly_rate * (1 + monthly_rate) ** months) / ((1 + monthly_rate) ** months - 1)\n",
    "    return f\"ì›” ìƒí™˜ê¸ˆì€ ì•½ {int(monthly_payment):,}ì›ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "\n",
    "# 2. ì…ë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class MonthlyPaymentInput(BaseModel):\n",
    "    principal: int         # ëŒ€ì¶œê¸ˆ\n",
    "    annual_rate: float     # ì—°ì´ììœ¨ (%)\n",
    "    years: int             # ëŒ€ì¶œê¸°ê°„ (ë…„)\n",
    "\n",
    "\n",
    "# 3. LangChain Tool ìƒì„±\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "monthly_payment_tool = StructuredTool.from_function(\n",
    "    func=calculate_monthly_payment,\n",
    "    name=\"monthly_payment\",\n",
    "    description=\"ëŒ€ì¶œê¸ˆ(principal), ì—°ì´ììœ¨(annual_rate), ê¸°ê°„(years)ì„ ì…ë ¥ë°›ì•„ ì›” ìƒí™˜ê¸ˆì„ ê³„ì‚°í•©ë‹ˆë‹¤.\",\n",
    "    args_schema=MonthlyPaymentInput,\n",
    ")\n",
    "\n",
    "\n",
    "# 4. ê¸°ì¡´ Tool ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "tools.append(monthly_payment_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e987b2b-f272-4409-94cb-586587c2718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"1ì–µ 5ì²œë§Œì›ì„ ì—° 4%ë¡œ 15ë…„ê°„ ê°šìœ¼ë©´ ì›” ìƒí™˜ê¸ˆ ì–¼ë§ˆì•¼?\"\n",
    "response = agent.run(query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd22ca7a-f95b-4c45-8338-59bc3ab8498c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict\n",
    "import re\n",
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥ ìˆ«ì ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def convert_korean_numbers(text):\n",
    "    units = {\"ì²œ\": 1_000, \"ë§Œ\": 10_000, \"ì–µ\": 100_000_000}\n",
    "\n",
    "    def replace(match):\n",
    "        num = float(match.group(1))\n",
    "        unit = match.group(2)\n",
    "        return str(int(num * units[unit]))\n",
    "\n",
    "    # group(1): ìˆ«ì, group(3): ë‹¨ìœ„\n",
    "    return re.sub(r\"(\\d+(?:\\.\\d+)?)(ì²œ|ë§Œ|ì–µ)\", replace, text)\n",
    "\n",
    "\n",
    "# ì „ì„¸ëŒ€ì¶œ í•œë„ ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_jeonse_limit(deposit: int, income: int, credit_grade: str) -> str:\n",
    "    credit_factor = {\"ìƒ\": 0.8, \"ì¤‘\": 0.6, \"í•˜\": 0.4}.get(credit_grade, 0.5)\n",
    "    limit = min(deposit * 0.8, income * 4 * credit_factor)\n",
    "    return f\"ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ” ì•½ {int(limit):,}ì›ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "# ìƒí™˜ê¸ˆ ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_monthly_payment(loan_amount: int, annual_interest_rate: float, years: int) -> str:\n",
    "    r = annual_interest_rate / 100 / 12\n",
    "    n = years * 12\n",
    "    if r == 0:\n",
    "        monthly = loan_amount / n\n",
    "    else:\n",
    "        monthly = loan_amount * r * (1 + r)**n / ((1 + r)**n - 1)\n",
    "    return f\"{loan_amount:,}ì›ì„ ì—° {annual_interest_rate}%ì˜ ì´ìë¡œ {years}ë…„ê°„ ê°šì„ ê²½ìš°, ë§¤ì›” ì•½ {int(monthly):,}ì›ì„ ìƒí™˜í•˜ì…”ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "# Pydantic ì…ë ¥ ìŠ¤í‚¤ë§ˆ\n",
    "def create_tool():\n",
    "    class JeonseLimitInput(BaseModel):\n",
    "        deposit: int\n",
    "        income: int\n",
    "        credit_grade: str\n",
    "\n",
    "    class MonthlyPaymentInput(BaseModel):\n",
    "        loan_amount: int\n",
    "        annual_interest_rate: float\n",
    "        years: int\n",
    "\n",
    "    tool1 = Tool.from_function(\n",
    "        name=\"jeonse_limit_calc\",\n",
    "        description=\"ì „ì„¸ëŒ€ì¶œ í•œë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (ì…ë ¥ê°’: deposit, income, credit_grade)\",\n",
    "        func=calculate_jeonse_limit,\n",
    "        args_schema=JeonseLimitInput\n",
    "    )\n",
    "\n",
    "    tool2 = Tool.from_function(\n",
    "        name=\"monthly_payment_calc\",\n",
    "        description=\"ì›” ìƒí™˜ê¸ˆì„ ê³„ì‚°í•©ë‹ˆë‹¤. (ì…ë ¥ê°’: loan_amount, annual_interest_rate, years)\",\n",
    "        func=calculate_monthly_payment,\n",
    "        args_schema=MonthlyPaymentInput\n",
    "    )\n",
    "\n",
    "    return [tool1, tool2]\n",
    "\n",
    "# LLM ì„¤ì • ë° Memory ì ìš©\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "tools = create_tool()\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ì§ˆì˜ í•¨ìˆ˜\n",
    "def ask_agent(query: str):\n",
    "    preprocessed = convert_korean_numbers(query)\n",
    "    return agent.run(preprocessed)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ\n",
    "query = \"ë³´ì¦ê¸ˆ 3ì–µì´ê³  ì—°ì†Œë“ 6ì²œë§Œì›, ì‹ ìš©ë“±ê¸‰ì€ ìƒì¸ë° ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ”?\"\n",
    "print(ask_agent(query))\n",
    "\n",
    "query2 = \"1ì–µ 5ì²œë§Œì›ì„ ì—° 4%ë¡œ 4ë…„ê°„ ê°šìœ¼ë©´?\"\n",
    "print(ask_agent(query2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3174cccd-a579-44bf-8011-bd61a0791236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic import BaseModel\n",
    "import re\n",
    "\n",
    "# âœ… ìˆ«ì ë‹¨ìœ„ ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def convert_korean_numbers(text: str) -> str:\n",
    "    units = {\"ì–µ\": 100_000_000, \"ë§Œ\": 10_000, \"ì²œ\": 1_000}\n",
    "    \n",
    "    def replace(match):\n",
    "        num_text = match.group()\n",
    "        total = 0\n",
    "        current = ''\n",
    "        for char in num_text:\n",
    "            if char.isdigit() or char == '.':\n",
    "                current += char\n",
    "            elif char in units:\n",
    "                if current == '':\n",
    "                    current = '1'\n",
    "                total += float(current) * units[char]\n",
    "                current = ''\n",
    "        return str(int(total))\n",
    "\n",
    "    # \"ë§Œì›\", \"ì²œì›\" ë“± ì ‘ë¯¸ì–´ ì œê±°\n",
    "    cleaned_text = re.sub(r\"(ë§Œì›|ì²œì›|ì›)\", \"\", text)\n",
    "    pattern = re.compile(r'(\\d+(?:\\.\\d+)?[ì²œë§Œì–µ])+')\n",
    "    return pattern.sub(replace, cleaned_text)\n",
    "\n",
    "\n",
    "# âœ… ì „ì„¸ëŒ€ì¶œ í•œë„ ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_jeonse_limit(deposit: int, income: int, credit_grade: str) -> str:\n",
    "    ratio = 0.8 if credit_grade == \"ìƒ\" else 0.6 if credit_grade == \"ì¤‘\" else 0.4\n",
    "    limit = int(min(deposit * ratio, income * 4))\n",
    "    return f\"ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ” ì•½ {limit:,}ì›ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "# âœ… ì›” ìƒí™˜ê¸ˆ ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_monthly_payment(loan_amount: int, annual_interest_rate: float, years: int) -> str:\n",
    "    r = annual_interest_rate / 100 / 12\n",
    "    n = years * 12\n",
    "    monthly = loan_amount * r / (1 - (1 + r) ** -n)\n",
    "    return (\n",
    "        f\"{loan_amount:,}ì›ì„ ì—° {annual_interest_rate}%ì˜ ì´ìë¡œ {years}ë…„ê°„ ê°šì„ ê²½ìš°, \"\n",
    "        f\"ë§¤ì›” ì•½ {int(monthly):,}ì›ì„ ìƒí™˜í•˜ì…”ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "    )\n",
    "\n",
    "# âœ… ì…ë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "class JeonseLimitInput(BaseModel):\n",
    "    deposit: int\n",
    "    income: int\n",
    "    credit_grade: str\n",
    "\n",
    "class MonthlyPaymentInput(BaseModel):\n",
    "    loan_amount: int\n",
    "    annual_interest_rate: float\n",
    "    years: int\n",
    "\n",
    "# âœ… Tool ë“±ë¡\n",
    "tools = [\n",
    "    StructuredTool.from_function(\n",
    "        name=\"jeonse_limit_calc\",\n",
    "        description=\"ì „ì„¸ëŒ€ì¶œ í•œë„ ê³„ì‚°ê¸° (ì…ë ¥: deposit, income, credit_grade)\",\n",
    "        args_schema=JeonseLimitInput,\n",
    "        func=calculate_jeonse_limit\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        name=\"monthly_payment_calc\",\n",
    "        description=\"ì›” ìƒí™˜ê¸ˆ ê³„ì‚°ê¸° (ì…ë ¥: loan_amount, annual_interest_rate, years)\",\n",
    "        args_schema=MonthlyPaymentInput,\n",
    "        func=calculate_monthly_payment\n",
    "    )\n",
    "]\n",
    "\n",
    "# âœ… LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0ã…‹ã…‹ã…‹ã…‹)\n",
    "\n",
    "# âœ… Memory ì„¤ì •\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# âœ… Agent ìƒì„±\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# âœ… ì „ì²˜ë¦¬ + ì‹¤í–‰ í•¨ìˆ˜\n",
    "def ask_agent(query: str):\n",
    "    preprocessed = convert_korean_numbers(query)\n",
    "    return agent.run(preprocessed)\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ\n",
    "print(ask_agent(\"ë³´ì¦ê¸ˆ 3ì–µì´ê³  ì—°ì†Œë“ 6ì²œë§Œì›, ì‹ ìš©ë“±ê¸‰ì€ ìƒì¸ë° ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ”?\"))\n",
    "print(ask_agent(\"1ì–µ5ì²œë§Œì›ì„ ì—° 4%ë¡œ 4ë…„ê°„ ê°šìœ¼ë©´?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead18bfb-bbee-4c75-a7df-0f16080a3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic import BaseModel\n",
    "import re\n",
    "import math\n",
    "\n",
    "# âœ… í•œê¸€ ìˆ«ì ë‹¨ìœ„ ì „ì²˜ë¦¬ (ì˜ˆ: 1ì–µ5ì²œë§Œì› â†’ 150000000)\n",
    "def convert_korean_numbers(text: str) -> str:\n",
    "    units = {\"ì²œ\": 1_000, \"ë§Œ\": 10_000, \"ì–µ\": 100_000_000}\n",
    "    pattern = re.compile(r\"(\\d+(?:\\.\\d+)?)([ì²œë§Œì–µ])\")\n",
    "\n",
    "    def replacer(match):\n",
    "        num = float(match.group(1))\n",
    "        unit = match.group(2)\n",
    "        return str(int(num * units[unit]))\n",
    "\n",
    "    return pattern.sub(replacer, text)\n",
    "\n",
    "# âœ… ë¬¸ë§¥ ê¸°ë°˜ ìˆ«ì ë‹¨ìœ„ ë³´ì™„ (ì˜ˆ: ì—°ì†Œë“ 6000 â†’ 60000000)\n",
    "def refine_contextual_units(text: str) -> str:\n",
    "    text = re.sub(r\"ì—°\\s*ì†Œë“\\s*(\\d{3,5})(?!\\d|[ì²œë§Œì–µ])\", lambda m: str(int(m.group(1)) * 10_000), text)\n",
    "    return text\n",
    "\n",
    "# âœ… ìµœì¢… ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def preprocess(text: str) -> str:\n",
    "    return convert_korean_numbers(refine_contextual_units(text))\n",
    "\n",
    "# âœ… ì „ì„¸ëŒ€ì¶œ í•œë„ ê³„ì‚°ê¸°\n",
    "def calculate_jeonse_limit(deposit: int, income: int, credit_grade: str) -> str:\n",
    "    ratio = 0.8 if credit_grade == \"ìƒ\" else 0.6 if credit_grade == \"ì¤‘\" else 0.4\n",
    "    limit = int(min(deposit * ratio, income * 4))\n",
    "    return f\"ë‹¹ì‹ ì˜ ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ” ì•½ {limit:,}ì›ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "# âœ… ì›” ìƒí™˜ê¸ˆ ê³„ì‚°ê¸°\n",
    "def calculate_monthly_payment(loan_amount: int, annual_interest_rate: float, years: int) -> str:\n",
    "    r = annual_interest_rate / 100 / 12\n",
    "    n = years * 12\n",
    "    monthly = loan_amount * r / (1 - (1 + r) ** -n)\n",
    "    return f\"{loan_amount:,}ì›ì„ ì—° {annual_interest_rate}%ì˜ ì´ìë¡œ {years}ë…„ê°„ ê°šì„ ê²½ìš°, ë§¤ì›” ì•½ {int(monthly):,}ì›ì„ ìƒí™˜í•˜ì…”ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "# âœ… ì…ë ¥ ìŠ¤í‚¤ë§ˆ\n",
    "class JeonseLimitInput(BaseModel):\n",
    "    deposit: int\n",
    "    income: int\n",
    "    credit_grade: str\n",
    "\n",
    "class MonthlyPaymentInput(BaseModel):\n",
    "    loan_amount: int\n",
    "    annual_interest_rate: float\n",
    "    years: int\n",
    "\n",
    "# âœ… Tool ì •ì˜\n",
    "tools = [\n",
    "    StructuredTool.from_function(\n",
    "        name=\"jeonse_limit_calc\",\n",
    "        description=\"ì „ì„¸ëŒ€ì¶œ í•œë„ ê³„ì‚°ê¸° (ì…ë ¥: deposit, income, credit_grade)\",\n",
    "        args_schema=JeonseLimitInput,        func=calculate_jeonse_limit\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        name=\"monthly_payment_calc\",\n",
    "        description=\"ì›” ìƒí™˜ê¸ˆ ê³„ì‚°ê¸° (ì…ë ¥: loan_amount, annual_interest_rate, years)\",\n",
    "        args_schema=MonthlyPaymentInput,\n",
    "        func=calculate_monthly_payment\n",
    "    )\n",
    "]\n",
    "\n",
    "# âœ… LLM + Memory + Agent ì„¤ì •\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# âœ… ì‹¤í–‰ í•¨ìˆ˜\n",
    "def ask_agent(query: str):\n",
    "    cleaned = preprocess(query)\n",
    "    return agent.run(cleaned)\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸\n",
    "print(ask_agent(\"ë³´ì¦ê¸ˆ 3ì–µì´ê³  ì—°ì†Œë“ 6ì²œë§Œì›, ì‹ ìš©ë“±ê¸‰ì€ ìƒì¸ë° ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ”?\"))\n",
    "print(ask_agent(\"150000000ì›ì„ ì—° 4%ë¡œ 4ë…„ê°„ ê°šìœ¼ë©´?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6962f3-741f-41df-8fca-fe6cc8a66895",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_agent(\"ë³´ì¦ê¸ˆ 3ì–µì´ê³  ì—°ì†Œë“ 60000000ì¸ë° í•œë„ëŠ”?\")\n",
    "# â†’ ì •ìƒ ì‘ë‹µ\n",
    "ask_agent(\"ê·¸ëŸ¼ ì´ìê°€ 4%ê³  4ë…„ ê°šìœ¼ë©´?\")\n",
    "# â†’ ì•ì˜ ëŒ€í™” ê¸°ì–µí•´ì„œ ëŒ€ì¶œê¸ˆ ê¸°ì¤€ìœ¼ë¡œ ì›” ìƒí™˜ê¸ˆ ê³„ì‚° ê°€ëŠ¥í•´ì•¼ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76bf2a4-d8ab-4293-b764-54faac264e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ë¬¸ë§¥ ìœ ì§€ + ê³„ì‚° ê¸°ëŠ¥ í†µí•©ëœ LangChain ëŒ€í™”í˜• ì—ì´ì „íŠ¸\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableMap\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from pydantic import BaseModel\n",
    "import math, re\n",
    "\n",
    "# âœ… ìˆ«ì ë‹¨ìœ„ ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def convert_korean_numbers(text: str) -> str:\n",
    "    units = {\"ì²œ\": 1_000, \"ë§Œ\": 10_000, \"ì–µ\": 100_000_000}\n",
    "\n",
    "    def repl(match):\n",
    "        parts = re.findall(r'(\\d+)([ì²œë§Œì–µ])?', match.group(0))\n",
    "        total = 0\n",
    "        for number, unit in parts:\n",
    "            total += int(number) * units.get(unit, 1)\n",
    "        return str(total)\n",
    "\n",
    "    return re.sub(r'\\d+[ì²œë§Œì–µ]?', repl, text)\n",
    "\n",
    "# âœ… ì „ì„¸ëŒ€ì¶œ í•œë„ ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_jeonse_limit(deposit: int, income: int, credit_grade: str) -> str:\n",
    "    ratio = 0.8 if credit_grade in [\"ìƒ\", \"A\"] else 0.6 if credit_grade in [\"ì¤‘\", \"B\"] else 0.4\n",
    "    limit = int(min(deposit * ratio, income * 4))\n",
    "    return f\"ë‹¹ì‹ ì˜ ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ” ì•½ {limit:,}ì›ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "# âœ… ì›” ìƒí™˜ê¸ˆ ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_monthly_payment(loan_amount: int, annual_interest_rate: float, years: int) -> str:\n",
    "    r = annual_interest_rate / 100 / 12\n",
    "    n = years * 12\n",
    "    monthly = loan_amount * r / (1 - (1 + r) ** -n)\n",
    "    return f\"{loan_amount:,}ì›ì„ ì—° {annual_interest_rate}%ì˜ ì´ìë¡œ {years}ë…„ê°„ ê°šì„ ê²½ìš°, ë§¤ì›” ì•½ {int(monthly):,}ì›ì„ ìƒí™˜í•˜ì…”ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "# âœ… Tool ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "class JeonseInput(BaseModel):\n",
    "    deposit: int\n",
    "    income: int\n",
    "    credit_grade: str\n",
    "\n",
    "class MonthlyInput(BaseModel):\n",
    "    loan_amount: int\n",
    "    annual_interest_rate: float\n",
    "    years: int\n",
    "\n",
    "# âœ… Tool ì •ì˜\n",
    "tools = [\n",
    "    StructuredTool.from_function(\n",
    "        name=\"jeonse_limit_calc\",\n",
    "        description=\"ì „ì„¸ëŒ€ì¶œ í•œë„ ê³„ì‚°ê¸°\",\n",
    "        args_schema=JeonseInput,\n",
    "        func=calculate_jeonse_limit,\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        name=\"monthly_payment_calc\",\n",
    "        description=\"ì›” ìƒí™˜ê¸ˆ ê³„ì‚°ê¸°\",\n",
    "        args_schema=MonthlyInput,\n",
    "        func=calculate_monthly_payment,\n",
    "    )\n",
    "]\n",
    "\n",
    "# âœ… LLM + Memory êµ¬ì„±\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì„±\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ê¸ˆìœµ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì´í•´í•˜ê³  í•„ìš”í•œ ê³„ì‚°ì„ ë„ì™€ì£¼ì„¸ìš”.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# âœ… Agent + Executor êµ¬ì„±\n",
    "agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)\n",
    "\n",
    "# âœ… ì‹¤í–‰ í•¨ìˆ˜\n",
    "def ask_agent(query):\n",
    "    query = convert_korean_numbers(query)\n",
    "    return agent_executor.invoke({\"input\": query})[\"output\"]\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸\n",
    "print(ask_agent(\"ë³´ì¦ê¸ˆ 3ì–µì´ê³  ì—°ì†Œë“ 6ì²œë§Œì›, ì‹ ìš©ë“±ê¸‰ì€ ìƒì¸ë° ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ”?\"))\n",
    "print(ask_agent(\"ê·¸ í•œë„ë¡œ 4% ì´ìë¡œ 4ë…„ ìƒí™˜í•˜ë©´ ë§¤ì›” ì–¼ë§ˆì•¼?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae2a65-8933-446e-bce8-a7e6939621d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import Tool, AgentExecutor, create_openai_functions_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic import BaseModel\n",
    "import re\n",
    "import math\n",
    "\n",
    "# âœ… ìˆ«ì ë‹¨ìœ„ ì „ì²˜ë¦¬\n",
    "def convert_korean_numbers(text: str) -> str:\n",
    "    units = {\"ì²œ\": 1_000, \"ë§Œ\": 10_000, \"ì–µ\": 100_000_000}\n",
    "    pattern = re.compile(r\"(\\d+)([ì²œë§Œì–µ])\")\n",
    "\n",
    "    def replace(match):\n",
    "        num = int(match.group(1))\n",
    "        unit = match.group(2)\n",
    "        return str(num * units[unit])\n",
    "\n",
    "    return pattern.sub(replace, text)\n",
    "\n",
    "# âœ… ì „ì„¸ëŒ€ì¶œ í•œë„ ê³„ì‚°\n",
    "def calculate_jeonse_limit(deposit: int, income: int, credit_grade: str) -> str:\n",
    "    ratio = 0.8 if credit_grade == \"ìƒ\" else 0.6 if credit_grade == \"ì¤‘\" else 0.4\n",
    "    limit = int(min(deposit * ratio, income * 4))\n",
    "    return f\"ë‹¹ì‹ ì˜ ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ” ì•½ {limit:,}ì›ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "# âœ… ì›” ìƒí™˜ê¸ˆ ê³„ì‚°\n",
    "def calculate_monthly_payment(loan_amount: int, annual_interest_rate: float, years: int) -> str:\n",
    "    r = annual_interest_rate / 100 / 12\n",
    "    n = years * 12\n",
    "    monthly = loan_amount * r / (1 - (1 + r) ** -n)\n",
    "    return f\"{loan_amount:,}ì›ì„ ì—° {annual_interest_rate}%ì˜ ì´ìë¡œ {years}ë…„ê°„ ê°šì„ ê²½ìš°, ë§¤ì›” ì•½ {int(monthly):,}ì›ì„ ìƒí™˜í•˜ì…”ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "# âœ… ì…ë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "class JeonseLimitInput(BaseModel):\n",
    "    deposit: int\n",
    "    income: int\n",
    "    credit_grade: str\n",
    "\n",
    "class MonthlyPaymentInput(BaseModel):\n",
    "    loan_amount: int\n",
    "    annual_interest_rate: float\n",
    "    years: int\n",
    "\n",
    "# âœ… Tool ì •ì˜\n",
    "tools = [\n",
    "    StructuredTool.from_function(\n",
    "        name=\"jeonse_limit_calc\",\n",
    "        description=\"ì „ì„¸ëŒ€ì¶œ í•œë„ ê³„ì‚°ê¸° (ì…ë ¥: deposit, income, credit_grade)\",\n",
    "        args_schema=JeonseLimitInput,\n",
    "        func=calculate_jeonse_limit\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        name=\"monthly_payment_calc\",\n",
    "        description=\"ì›” ìƒí™˜ê¸ˆ ê³„ì‚°ê¸° (ì…ë ¥: loan_amount, annual_interest_rate, years)\",\n",
    "        args_schema=MonthlyPaymentInput,\n",
    "        func=calculate_monthly_payment\n",
    "    )\n",
    "]\n",
    "\n",
    "# âœ… LLM ë° ë©”ëª¨ë¦¬\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (agent_scratchpad í¬í•¨)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ê¸ˆìœµ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì´í•´í•˜ê³  í•„ìš”í•œ ê³„ì‚°ì„ ë„ì™€ì£¼ì„¸ìš”.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# âœ… Agent ë° Executor êµ¬ì„±\n",
    "agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)\n",
    "\n",
    "# âœ… ì‹¤í–‰ í•¨ìˆ˜\n",
    "def ask_agent(query: str):\n",
    "    preprocessed = convert_korean_numbers(query)\n",
    "    return agent_executor.invoke({\"input\": preprocessed})[\"output\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721328c-d62c-4c3f-9c1f-f6d5b3632fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ask_agent(\"ë³´ì¦ê¸ˆ 3ì–µì´ê³  ì—°ì†Œë“ 6ì²œë§Œì›, ì‹ ìš©ë“±ê¸‰ì€ ìƒì¸ë° ì „ì„¸ëŒ€ì¶œ í•œë„ëŠ”?\"))\n",
    "print(ask_agent(\"ê·¸ëŸ¼ ì´ í•œë„ë¡œ 4%ë¡œ 4ë…„ê°„ ê°šìœ¼ë©´ ì›” ì–¼ë§ˆì•¼?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f94dd-052f-4153-b8b3-9ad56e06cffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
